{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rmMcZ6M23fIt"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CY32YINu3jSK"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import load_model, save_model, clone_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vRqhqoTr3399"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m0SvKp4x8HUu"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import ImageOps, ImageEnhance, ImageFilter, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_lplUPCl8Lrv"
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U0kFPcjM-hwv"
   },
   "outputs": [],
   "source": [
    "image_size = (32, 32)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ndxtfbyEOg4"
   },
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0y4W0TM64Oez"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "leGdJv0ZIfuF",
    "outputId": "bd3069cb-213f-42ea-a6d4-0b76180eb270"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-05 00:21:43--  https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
      "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 170498071 (163M) [application/x-gzip]\n",
      "Saving to: ‘cifar-10-python.tar.gz’\n",
      "\n",
      "cifar-10-python.tar 100%[===================>] 162.60M  5.09MB/s    in 23s     \n",
      "\n",
      "2019-05-05 00:22:07 (6.94 MB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n",
      "\n",
      "cifar-10-batches-py/\n",
      "cifar-10-batches-py/data_batch_4\n",
      "cifar-10-batches-py/readme.html\n",
      "cifar-10-batches-py/test_batch\n",
      "cifar-10-batches-py/data_batch_3\n",
      "cifar-10-batches-py/batches.meta\n",
      "cifar-10-batches-py/data_batch_2\n",
      "cifar-10-batches-py/data_batch_5\n",
      "cifar-10-batches-py/data_batch_1\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "!tar -xvzf cifar-10-python.tar.gz\n",
    "!rm cifar-10-python.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "59InDTAGIjfj"
   },
   "outputs": [],
   "source": [
    "data_dir = \"cifar-10-batches-py/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IIBxcjL95V2Q"
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo)\n",
    "    return dict\n",
    "\n",
    "# Load Train Data\n",
    "train_data_dirs = [data_dir+\"data_batch_{}\".format(i) for i in range(1,6)]\n",
    "\n",
    "raw_data = [unpickle(path) for path in train_data_dirs]\n",
    "train_labels = np.array(sum([batch[b'labels'] for batch in raw_data], []))\n",
    "train_data = np.vstack([batch[b'data'] for batch in raw_data])\n",
    "train_data = np.moveaxis(train_data.reshape(-1,3,32,32),1,-1)\n",
    "\n",
    "# Load Test Data\n",
    "test_data_dir = data_dir+\"test_batch\"\n",
    "\n",
    "raw_data = unpickle(test_data_dir)\n",
    "test_labels = np.array(raw_data[b'labels'])\n",
    "test_data = raw_data[b'data'] \n",
    "test_data = np.moveaxis(test_data.reshape(-1,3,32,32),1,-1)\n",
    "\n",
    "# Load Label Names\n",
    "label_names = unpickle(data_dir+\"batches.meta\")[b'label_names']\n",
    "\n",
    "# Preprocess x and y \n",
    "X_train = [Image.fromarray((np.uint8(data))) for data in train_data]\n",
    "X_train = train_data/ 255.\n",
    "X_test = test_data/ 255.\n",
    "\n",
    "y_train = np.eye(10)[train_labels]\n",
    "y_test = np.eye(10)[test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_MYBAR5p9bvo"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MhfZHXab91ab"
   },
   "source": [
    "# Make Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wrYcRoV-93JD"
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator()\n",
    "test_generator = test_datagen.flow(X_test, y_test)\n",
    "\n",
    "validation_generator = test_datagen.flow(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 712
    },
    "colab_type": "code",
    "id": "BLxfycDi_Nt3",
    "outputId": "32e2a591-c77f-40a8-905e-2224287c4f9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 256)       7168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 15, 15, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 5, 5, 128)         131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 5, 5, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 1,150,410\n",
      "Trainable params: 1,148,746\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 0.8426\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow(X_train, y_train, \n",
    "                                      batch_size=batch_size)\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(256, (3, 3), \n",
    "                        input_shape=(image_size[0], image_size[1], 3),\n",
    "                        data_format='channels_last',\n",
    "                        activation='elu', kernel_initializer='he_normal'))\n",
    "model.add(layers.MaxPool2D(2, 2))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(256, (3, 3),\n",
    "                        activation='elu',\n",
    "                        kernel_initializer='he_normal'))\n",
    "model.add(layers.MaxPool2D(2, 2))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Conv2D(128, (2, 2),\n",
    "                        activation='elu',\n",
    "                        kernel_initializer='he_normal'))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "model.add(layers.Dense(128,\n",
    "                       activation='elu',\n",
    "                       kernel_initializer='he_normal'))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Dense(64,\n",
    "                       activation='elu',\n",
    "                       kernel_initializer='he_normal'))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Dense(num_classes, \n",
    "                       activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dK2KYPlLC6Gw"
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('checkpoint_model_%i.h5' % (model_num), \n",
    "                              monitor='val_loss', \n",
    "                              verbose=False, save_best_only=True, \n",
    "                              save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "32wtAT-a_NwG"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XfdHrmKU_O1Y"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3998
    },
    "colab_type": "code",
    "id": "uuYxXwk496ny",
    "outputId": "2f4302aa-37a4-4e53-f71d-f7788a87d67f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/150\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 3.8302 - acc: 0.1893\n",
      "313/313 [==============================] - 55s 175ms/step - loss: 1.9393 - acc: 0.2978 - val_loss: 3.8302 - val_acc: 0.1893\n",
      "Epoch 2/150\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 1.5590 - acc: 0.4141\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 1.7549 - acc: 0.3550 - val_loss: 1.5590 - val_acc: 0.4141\n",
      "Epoch 3/150\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 1.4690 - acc: 0.4803\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 1.6103 - acc: 0.4152 - val_loss: 1.4690 - val_acc: 0.4803\n",
      "Epoch 4/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.5420 - acc: 0.4572\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 1.5004 - acc: 0.4575 - val_loss: 1.5420 - val_acc: 0.4572\n",
      "Epoch 5/150\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 1.3522 - acc: 0.5136\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 1.4222 - acc: 0.4890 - val_loss: 1.3522 - val_acc: 0.5136\n",
      "Epoch 6/150\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 1.4212 - acc: 0.5182\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 1.3437 - acc: 0.5189 - val_loss: 1.4212 - val_acc: 0.5182\n",
      "Epoch 7/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.4820 - acc: 0.5178\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 1.2810 - acc: 0.5439 - val_loss: 1.4820 - val_acc: 0.5178\n",
      "Epoch 8/150\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 1.1375 - acc: 0.6036\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 1.2198 - acc: 0.5662 - val_loss: 1.1375 - val_acc: 0.6036\n",
      "Epoch 9/150\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 1.1944 - acc: 0.6035\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 1.1745 - acc: 0.5831 - val_loss: 1.1944 - val_acc: 0.6035\n",
      "Epoch 10/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 1.3298 - acc: 0.5654\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 1.1424 - acc: 0.5951 - val_loss: 1.3298 - val_acc: 0.5654\n",
      "Epoch 11/150\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.9951 - acc: 0.6555\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 1.1005 - acc: 0.6127 - val_loss: 0.9951 - val_acc: 0.6555\n",
      "Epoch 12/150\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.9418 - acc: 0.6708\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 1.0760 - acc: 0.6193 - val_loss: 0.9418 - val_acc: 0.6708\n",
      "Epoch 13/150\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.9178 - acc: 0.6769\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 1.0366 - acc: 0.6320 - val_loss: 0.9178 - val_acc: 0.6769\n",
      "Epoch 14/150\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 1.0919 - acc: 0.6389\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 1.0171 - acc: 0.6397 - val_loss: 1.0919 - val_acc: 0.6389\n",
      "Epoch 15/150\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 1.0427 - acc: 0.6640\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.9938 - acc: 0.6506 - val_loss: 1.0427 - val_acc: 0.6640\n",
      "Epoch 16/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.9127 - acc: 0.6894\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.9725 - acc: 0.6600 - val_loss: 0.9127 - val_acc: 0.6894\n",
      "Epoch 17/150\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.8842 - acc: 0.6971\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.9491 - acc: 0.6654 - val_loss: 0.8842 - val_acc: 0.6971\n",
      "Epoch 18/150\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.8469 - acc: 0.7098\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.9328 - acc: 0.6725 - val_loss: 0.8469 - val_acc: 0.7098\n",
      "Epoch 19/150\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.9084 - acc: 0.6912\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 0.9244 - acc: 0.6740 - val_loss: 0.9084 - val_acc: 0.6912\n",
      "Epoch 20/150\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.9307 - acc: 0.6888\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.9093 - acc: 0.6808 - val_loss: 0.9307 - val_acc: 0.6888\n",
      "Epoch 21/150\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.8160 - acc: 0.7223\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.8839 - acc: 0.6903 - val_loss: 0.8160 - val_acc: 0.7223\n",
      "Epoch 22/150\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.8316 - acc: 0.7225\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.8734 - acc: 0.6941 - val_loss: 0.8316 - val_acc: 0.7225\n",
      "Epoch 23/150\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.8793 - acc: 0.7022\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.8590 - acc: 0.7011 - val_loss: 0.8793 - val_acc: 0.7022\n",
      "Epoch 24/150\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.9035 - acc: 0.7073\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 0.8403 - acc: 0.7075 - val_loss: 0.9035 - val_acc: 0.7073\n",
      "Epoch 25/150\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.7678 - acc: 0.7407\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 0.8555 - acc: 0.7023 - val_loss: 0.7678 - val_acc: 0.7407\n",
      "Epoch 26/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.8814 - acc: 0.7013\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.8328 - acc: 0.7084 - val_loss: 0.8814 - val_acc: 0.7013\n",
      "Epoch 27/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.7370 - acc: 0.7487\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.8163 - acc: 0.7167 - val_loss: 0.7370 - val_acc: 0.7487\n",
      "Epoch 28/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.8782 - acc: 0.7155\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.8043 - acc: 0.7195 - val_loss: 0.8782 - val_acc: 0.7155\n",
      "Epoch 29/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.7519 - acc: 0.7476\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 0.7952 - acc: 0.7199 - val_loss: 0.7519 - val_acc: 0.7476\n",
      "Epoch 30/150\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.7744 - acc: 0.7420\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.7849 - acc: 0.7278 - val_loss: 0.7744 - val_acc: 0.7420\n",
      "Epoch 31/150\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.8086 - acc: 0.7380\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.7794 - acc: 0.7287 - val_loss: 0.8086 - val_acc: 0.7380\n",
      "Epoch 32/150\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.7669 - acc: 0.7490\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.7696 - acc: 0.7310 - val_loss: 0.7669 - val_acc: 0.7490\n",
      "Epoch 33/150\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.7085 - acc: 0.7601\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 0.7602 - acc: 0.7352 - val_loss: 0.7085 - val_acc: 0.7601\n",
      "Epoch 34/150\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.6809 - acc: 0.7664\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 0.7535 - acc: 0.7386 - val_loss: 0.6809 - val_acc: 0.7664\n",
      "Epoch 35/150\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.6735 - acc: 0.7738\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.7447 - acc: 0.7408 - val_loss: 0.6735 - val_acc: 0.7738\n",
      "Epoch 36/150\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.7366 - acc: 0.7548\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 0.7466 - acc: 0.7433 - val_loss: 0.7366 - val_acc: 0.7548\n",
      "Epoch 37/150\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.7175 - acc: 0.7633\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.7353 - acc: 0.7435 - val_loss: 0.7175 - val_acc: 0.7633\n",
      "Epoch 38/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.7164 - acc: 0.7610\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.7274 - acc: 0.7454 - val_loss: 0.7164 - val_acc: 0.7610\n",
      "Epoch 39/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.7049 - acc: 0.7654\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.7095 - acc: 0.7534 - val_loss: 0.7049 - val_acc: 0.7654\n",
      "Epoch 40/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.7513 - acc: 0.7529\n",
      "313/313 [==============================] - 46s 149ms/step - loss: 0.7105 - acc: 0.7522 - val_loss: 0.7513 - val_acc: 0.7529\n",
      "Epoch 41/150\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.6312 - acc: 0.7866\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 0.7096 - acc: 0.7546 - val_loss: 0.6312 - val_acc: 0.7866\n",
      "Epoch 42/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.7201 - acc: 0.7652\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.7008 - acc: 0.7566 - val_loss: 0.7201 - val_acc: 0.7652\n",
      "Epoch 43/150\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.8004 - acc: 0.7421\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 0.6938 - acc: 0.7575 - val_loss: 0.8004 - val_acc: 0.7421\n",
      "Epoch 44/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.6717 - acc: 0.7837\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.6894 - acc: 0.7605 - val_loss: 0.6717 - val_acc: 0.7837\n",
      "Epoch 45/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.6435 - acc: 0.7839\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.6826 - acc: 0.7626 - val_loss: 0.6435 - val_acc: 0.7839\n",
      "Epoch 46/150\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.6328 - acc: 0.7898\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.6823 - acc: 0.7622 - val_loss: 0.6328 - val_acc: 0.7898\n",
      "Epoch 47/150\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.7142 - acc: 0.7658\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.6726 - acc: 0.7632 - val_loss: 0.7142 - val_acc: 0.7658\n",
      "Epoch 48/150\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.6466 - acc: 0.7894\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 0.6753 - acc: 0.7668 - val_loss: 0.6466 - val_acc: 0.7894\n",
      "Epoch 49/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.6995 - acc: 0.7727\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 0.6649 - acc: 0.7696 - val_loss: 0.6995 - val_acc: 0.7727\n",
      "Epoch 50/150\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.7419 - acc: 0.7604\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.6734 - acc: 0.7661 - val_loss: 0.7419 - val_acc: 0.7604\n",
      "Epoch 51/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.6467 - acc: 0.7914\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.6564 - acc: 0.7715 - val_loss: 0.6467 - val_acc: 0.7914\n",
      "Epoch 52/150\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.6342 - acc: 0.7899\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.6579 - acc: 0.7708 - val_loss: 0.6342 - val_acc: 0.7899\n",
      "Epoch 53/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.6825 - acc: 0.7731\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.6515 - acc: 0.7723 - val_loss: 0.6825 - val_acc: 0.7731\n",
      "Epoch 54/150\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.5990 - acc: 0.8020\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.6452 - acc: 0.7761 - val_loss: 0.5990 - val_acc: 0.8020\n",
      "Epoch 55/150\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.7932 - acc: 0.7549\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.6365 - acc: 0.7781 - val_loss: 0.7932 - val_acc: 0.7549\n",
      "Epoch 56/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.6899 - acc: 0.7762\n",
      "313/313 [==============================] - 46s 149ms/step - loss: 0.6295 - acc: 0.7814 - val_loss: 0.6899 - val_acc: 0.7762\n",
      "Epoch 57/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.6874 - acc: 0.7736\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 0.6335 - acc: 0.7817 - val_loss: 0.6874 - val_acc: 0.7736\n",
      "Epoch 58/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.5888 - acc: 0.8039\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 0.6305 - acc: 0.7786 - val_loss: 0.5888 - val_acc: 0.8039\n",
      "Epoch 59/150\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.6432 - acc: 0.7931\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.6193 - acc: 0.7847 - val_loss: 0.6432 - val_acc: 0.7931\n",
      "Epoch 60/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.7333 - acc: 0.7665\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 0.6194 - acc: 0.7844 - val_loss: 0.7333 - val_acc: 0.7665\n",
      "Epoch 61/150\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.5791 - acc: 0.8067\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.6181 - acc: 0.7840 - val_loss: 0.5791 - val_acc: 0.8067\n",
      "Epoch 62/150\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.5859 - acc: 0.8069\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.6287 - acc: 0.7817 - val_loss: 0.5859 - val_acc: 0.8069\n",
      "Epoch 63/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.7613 - acc: 0.7695\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 0.6121 - acc: 0.7872 - val_loss: 0.7613 - val_acc: 0.7695\n",
      "Epoch 64/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.5713 - acc: 0.8111\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 0.6049 - acc: 0.7896 - val_loss: 0.5713 - val_acc: 0.8111\n",
      "Epoch 65/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.6836 - acc: 0.7825\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 0.6113 - acc: 0.7879 - val_loss: 0.6836 - val_acc: 0.7825\n",
      "Epoch 66/150\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.5781 - acc: 0.8083\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 0.5983 - acc: 0.7926 - val_loss: 0.5781 - val_acc: 0.8083\n",
      "Epoch 67/150\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.6535 - acc: 0.7844\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 0.6059 - acc: 0.7883 - val_loss: 0.6535 - val_acc: 0.7844\n",
      "Epoch 68/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.5825 - acc: 0.8128\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.5947 - acc: 0.7916 - val_loss: 0.5825 - val_acc: 0.8128\n",
      "Epoch 69/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.6306 - acc: 0.7973\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 0.5942 - acc: 0.7933 - val_loss: 0.6306 - val_acc: 0.7973\n",
      "Epoch 70/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.6316 - acc: 0.7971\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 0.5917 - acc: 0.7940 - val_loss: 0.6316 - val_acc: 0.7971\n",
      "Epoch 71/150\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.6476 - acc: 0.7892\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.5902 - acc: 0.7932 - val_loss: 0.6476 - val_acc: 0.7892\n",
      "Epoch 72/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.6604 - acc: 0.7865\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 0.5820 - acc: 0.7980 - val_loss: 0.6604 - val_acc: 0.7865\n",
      "Epoch 73/150\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.6045 - acc: 0.8017\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.5844 - acc: 0.7966 - val_loss: 0.6045 - val_acc: 0.8017\n",
      "Epoch 74/150\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.5836 - acc: 0.8087\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.5778 - acc: 0.7983 - val_loss: 0.5836 - val_acc: 0.8087\n",
      "Epoch 75/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.7407 - acc: 0.7609\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 0.6357 - acc: 0.7786 - val_loss: 0.7407 - val_acc: 0.7609\n",
      "Epoch 76/150\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.5999 - acc: 0.8029\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 0.5817 - acc: 0.7976 - val_loss: 0.5999 - val_acc: 0.8029\n",
      "Epoch 77/150\n",
      "307/313 [============================>.] - ETA: 0s - loss: 0.5710 - acc: 0.8006"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch = len(X_train) // batch_size,\n",
    "                    validation_data = validation_generator, \n",
    "                    validation_steps = len(X_val) // batch_size,\n",
    "                    epochs=epochs, callbacks=[checkpoint])#, mixup])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HM08TfMvZXZH"
   },
   "outputs": [],
   "source": [
    "model.save('fit_model_%i.h5' % (model_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pys2S3cwQxvM"
   },
   "outputs": [],
   "source": [
    "model.load_weights('checkpoint_model_%i.h5' % (model_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mMbp-b24N_Zk"
   },
   "outputs": [],
   "source": [
    "model.save('loaded_model_%i.h5' % (model_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RzTneUyPaKeP"
   },
   "outputs": [],
   "source": [
    "metrics = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UANNG01KaKMl"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tWqDwddtZd7J"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 9))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(len(model.history.history['loss'])), model.history.history['loss'], \n",
    "         label='Train Loss')\n",
    "plt.plot(range(len(model.history.history['loss'])), model.history.history['val_loss'], \n",
    "         label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cross entropy')\n",
    "plt.text(0.6 * epochs, 0.75 * max(model.history.history['loss']),\n",
    "         'Test loss = %.4f' %(metrics[0]))\n",
    "plt.legend(loc='best')\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(len(model.history.history['loss'])), model.history.history['acc'], \n",
    "         label='Train Accuracy')\n",
    "plt.plot(range(len(model.history.history['loss'])), model.history.history['val_acc'], \n",
    "         label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.text(0.6 * epochs, 0.8 * max(model.history.history['acc']),\n",
    "         'Test Accuracy = %.4f' %(metrics[1]))\n",
    "plt.legend(loc='best')\n",
    "\n",
    "\n",
    "plt.savefig('training_metrics_%i.pdf' %(model_num))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g9XjqgPwdkE3"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-qSiZRiWd3fJ"
   },
   "outputs": [],
   "source": [
    "classes = ['Plane', 'Car', 'Bird', 'Cat', 'Deer',\n",
    "           'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
    "pred_sample = model.predict(X_test[:3])\n",
    "preds = []\n",
    "trues = []\n",
    "for i in range(len(pred_sample)):\n",
    "  p = list(pred_sample[i])\n",
    "  y = list(y_test[i])\n",
    "  this_pred = classes[p.index(max(p))]\n",
    "  this_true = classes[y.index(max(y))]\n",
    "  preds.append(this_pred)\n",
    "  trues.append(this_true)\n",
    "  print(this_pred, this_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ArZ3oa_yd3hz"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Predicted %s, Actually %s' % (preds[0], trues[0]))\n",
    "plt.imshow(X_test[0])\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('Predicted %s, Actually %s' % (preds[1], trues[1]))\n",
    "plt.imshow(X_test[1])\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('Predicted %s, Actually %s' % (preds[2], trues[2]))\n",
    "plt.imshow(X_test[2])\n",
    "\n",
    "plt.savefig('prediction_sample_%i.pdf' % (model_num))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fHC5r-Tdd4NY"
   },
   "source": [
    "# Feature Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zUdp78mSd6Nd"
   },
   "outputs": [],
   "source": [
    "# Get convolutional layer outputs\n",
    "conv_layer_outputs = []\n",
    "for layer in model.layers:\n",
    "  if 'conv' in layer.name:\n",
    "    conv_layer_outputs.append(layer.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IVtip0K8eYa-"
   },
   "outputs": [],
   "source": [
    "output_model = models.Model(inputs=model.input, outputs=conv_layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TcVqW9tQkvGQ"
   },
   "outputs": [],
   "source": [
    "activation_indices = np.random.randint(0, len(y_test), size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RxrEtpMufD_Y"
   },
   "outputs": [],
   "source": [
    "activation_images = X_test[activation_indices]\n",
    "activations = output_model.predict(activation_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Si3N4GUVc9uB"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "plt.subplot(4, 3, 1)\n",
    "plt.imshow(activation_images[0])\n",
    "\n",
    "plt.subplot(4, 3, 2)\n",
    "plt.imshow(activation_images[1])\n",
    "\n",
    "plt.subplot(4, 3, 3)\n",
    "plt.imshow(activation_images[2])\n",
    "\n",
    "\n",
    "plt.subplot(4, 3, 4)\n",
    "plt.imshow(activations[0][0, :, :, 0])\n",
    "\n",
    "plt.subplot(4, 3, 5)\n",
    "plt.imshow(activations[0][1, :, :, 0])\n",
    "\n",
    "plt.subplot(4, 3, 6)\n",
    "plt.imshow(activations[0][2, :, :, 0])\n",
    "\n",
    "plt.subplot(4, 3, 7)\n",
    "plt.imshow(activations[0][0, :, :, 21])\n",
    "\n",
    "plt.subplot(4, 3, 8)\n",
    "plt.imshow(activations[0][1, :, :, 21])\n",
    "\n",
    "plt.subplot(4, 3, 9)\n",
    "plt.imshow(activations[0][2, :, :, 21])\n",
    "\n",
    "plt.subplot(4, 3, 10)\n",
    "plt.imshow(activations[0][0, :, :, 137])\n",
    "\n",
    "plt.subplot(4, 3, 11)\n",
    "plt.imshow(activations[0][1, :, :, 137])\n",
    "\n",
    "plt.subplot(4, 3, 12)\n",
    "plt.imshow(activations[0][2, :, :, 137])\n",
    "\n",
    "\n",
    "plt.savefig('first_layer_activations_0_21_137_model%i.pdf' % (model_num))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0MvxdOwklbpN"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "plt.subplot(4, 3, 1)\n",
    "plt.imshow(activation_images[0])\n",
    "\n",
    "plt.subplot(4, 3, 2)\n",
    "plt.imshow(activation_images[1])\n",
    "\n",
    "plt.subplot(4, 3, 3)\n",
    "plt.imshow(activation_images[2])\n",
    "\n",
    "\n",
    "plt.subplot(4, 3, 4)\n",
    "plt.imshow(activations[0][0, :, :, 1])\n",
    "\n",
    "plt.subplot(4, 3, 5)\n",
    "plt.imshow(activations[0][1, :, :, 1])\n",
    "\n",
    "plt.subplot(4, 3, 6)\n",
    "plt.imshow(activations[0][2, :, :, 1])\n",
    "\n",
    "plt.subplot(4, 3, 7)\n",
    "plt.imshow(activations[0][0, :, :, 2])\n",
    "\n",
    "plt.subplot(4, 3, 8)\n",
    "plt.imshow(activations[0][1, :, :, 2])\n",
    "\n",
    "plt.subplot(4, 3, 9)\n",
    "plt.imshow(activations[0][2, :, :, 2])\n",
    "\n",
    "plt.subplot(4, 3, 10)\n",
    "plt.imshow(activations[0][0, :, :, 3])\n",
    "\n",
    "plt.subplot(4, 3, 11)\n",
    "plt.imshow(activations[0][1, :, :, 3])\n",
    "\n",
    "plt.subplot(4, 3, 12)\n",
    "plt.imshow(activations[0][2, :, :, 3])\n",
    "\n",
    "\n",
    "plt.savefig('first_layer_activations_1to3_%i.pdf' %(model_num))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pn2BFmHxo5hz"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "plt.subplot(4, 3, 1)\n",
    "plt.imshow(activation_images[0])\n",
    "\n",
    "plt.subplot(4, 3, 2)\n",
    "plt.imshow(activation_images[1])\n",
    "\n",
    "plt.subplot(4, 3, 3)\n",
    "plt.imshow(activation_images[2])\n",
    "\n",
    "\n",
    "plt.subplot(4, 3, 4)\n",
    "plt.imshow(activations[0][0, :, :, 4])\n",
    "\n",
    "plt.subplot(4, 3, 5)\n",
    "plt.imshow(activations[0][1, :, :, 4])\n",
    "\n",
    "plt.subplot(4, 3, 6)\n",
    "plt.imshow(activations[0][2, :, :, 4])\n",
    "\n",
    "plt.subplot(4, 3, 7)\n",
    "plt.imshow(activations[0][0, :, :, 5])\n",
    "\n",
    "plt.subplot(4, 3, 8)\n",
    "plt.imshow(activations[0][1, :, :, 5])\n",
    "\n",
    "plt.subplot(4, 3, 9)\n",
    "plt.imshow(activations[0][2, :, :, 5])\n",
    "\n",
    "plt.subplot(4, 3, 10)\n",
    "plt.imshow(activations[0][0, :, :, 6])\n",
    "\n",
    "plt.subplot(4, 3, 11)\n",
    "plt.imshow(activations[0][1, :, :, 6])\n",
    "\n",
    "plt.subplot(4, 3, 12)\n",
    "plt.imshow(activations[0][2, :, :, 6])\n",
    "\n",
    "\n",
    "plt.savefig('first_layer_activations_4to6_%i.pdf' % (model_num))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wTQ3RsM3ofQq"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "plt.subplot(4, 3, 1)\n",
    "plt.imshow(activation_images[0])\n",
    "\n",
    "plt.subplot(4, 3, 2)\n",
    "plt.imshow(activation_images[1])\n",
    "\n",
    "plt.subplot(4, 3, 3)\n",
    "plt.imshow(activation_images[2])\n",
    "\n",
    "\n",
    "plt.subplot(4, 3, 4)\n",
    "plt.imshow(activations[1][0, :, :, 1])\n",
    "\n",
    "plt.subplot(4, 3, 5)\n",
    "plt.imshow(activations[1][1, :, :, 1])\n",
    "\n",
    "plt.subplot(4, 3, 6)\n",
    "plt.imshow(activations[1][2, :, :, 1])\n",
    "\n",
    "plt.subplot(4, 3, 7)\n",
    "plt.imshow(activations[1][0, :, :, 2])\n",
    "\n",
    "plt.subplot(4, 3, 8)\n",
    "plt.imshow(activations[1][1, :, :, 2])\n",
    "\n",
    "plt.subplot(4, 3, 9)\n",
    "plt.imshow(activations[1][2, :, :, 2])\n",
    "\n",
    "plt.subplot(4, 3, 10)\n",
    "plt.imshow(activations[1][0, :, :, 3])\n",
    "\n",
    "plt.subplot(4, 3, 11)\n",
    "plt.imshow(activations[1][1, :, :, 3])\n",
    "\n",
    "plt.subplot(4, 3, 12)\n",
    "plt.imshow(activations[1][2, :, :, 3])\n",
    "\n",
    "\n",
    "plt.savefig('second_layer_activations_1to3_%i.pdf' % (model_num))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_LHG1RPHwI7j"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "plt.subplot(4, 3, 1)\n",
    "plt.imshow(activation_images[0])\n",
    "\n",
    "plt.subplot(4, 3, 2)\n",
    "plt.imshow(activation_images[1])\n",
    "\n",
    "plt.subplot(4, 3, 3)\n",
    "plt.imshow(activation_images[2])\n",
    "\n",
    "\n",
    "plt.subplot(4, 3, 4)\n",
    "plt.imshow(activations[2][0, :, :, 1])\n",
    "\n",
    "plt.subplot(4, 3, 5)\n",
    "plt.imshow(activations[2][1, :, :, 1])\n",
    "\n",
    "plt.subplot(4, 3, 6)\n",
    "plt.imshow(activations[2][2, :, :, 1])\n",
    "\n",
    "plt.subplot(4, 3, 7)\n",
    "plt.imshow(activations[2][0, :, :, 2])\n",
    "\n",
    "plt.subplot(4, 3, 8)\n",
    "plt.imshow(activations[2][1, :, :, 2])\n",
    "\n",
    "plt.subplot(4, 3, 9)\n",
    "plt.imshow(activations[2][2, :, :, 2])\n",
    "\n",
    "plt.subplot(4, 3, 10)\n",
    "plt.imshow(activations[2][0, :, :, 3])\n",
    "\n",
    "plt.subplot(4, 3, 11)\n",
    "plt.imshow(activations[2][1, :, :, 3])\n",
    "\n",
    "plt.subplot(4, 3, 12)\n",
    "plt.imshow(activations[2][2, :, :, 3])\n",
    "\n",
    "\n",
    "plt.savefig('third_layer_activations_1to3_%i.pdf' % (model_num))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xAlBsyvCemoF"
   },
   "outputs": [],
   "source": [
    "# plt.close()\n",
    "# plt.figure(figsize=(16, 16))\n",
    "\n",
    "# plt.subplot(len(conv_layer_outputs) + 1, len(activation_images), 1)\n",
    "# plt.imshow(activation_images[0])\n",
    "\n",
    "# plt.subplot(len(conv_layer_outputs) + 1, len(activation_images), 2)\n",
    "# plt.imshow(activation_images[1])\n",
    "\n",
    "# plt.subplot(len(conv_layer_outputs) + 1, len(activation_images), 3)\n",
    "# plt.imshow(activation_images[2])\n",
    "\n",
    "# channel = 3\n",
    "# for i in range(len(conv_layer_outputs)):\n",
    "#   for j in range(len(activation_images)):\n",
    "#     plt.subplot(len(conv_layer_outputs) + 1, len(activation_images), \n",
    "#                 len(activation_images) * (1 + i) + 1 + j)\n",
    "#     print(len(activation_images) * (1 + i) + 1 + j)\n",
    "# #     this_image = activations[i][j, :, :, channel]\n",
    "#     plt.matshow(activations[i][j, :, :, channel], cmap='viridis')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NtV3YD5ntaHg"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "plt.subplot(4, 3, 1)\n",
    "plt.imshow(activation_images[0])\n",
    "\n",
    "plt.subplot(4, 3, 2)\n",
    "plt.imshow(activation_images[1])\n",
    "\n",
    "plt.subplot(4, 3, 3)\n",
    "plt.imshow(activation_images[2])\n",
    "\n",
    "\n",
    "plt.subplot(4, 3, 4)\n",
    "plt.imshow(activations[0][0, :, :, :3])\n",
    "\n",
    "plt.subplot(4, 3, 5)\n",
    "plt.imshow(activations[0][1, :, :, :3])\n",
    "\n",
    "plt.subplot(4, 3, 6)\n",
    "plt.imshow(activations[0][2, :, :, :3])\n",
    "\n",
    "plt.savefig('stacked_first_layer_0to2_%i.pdf' % (model_num))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j5oa4Al8vU8E"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "data2040_final_project_cnn.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
